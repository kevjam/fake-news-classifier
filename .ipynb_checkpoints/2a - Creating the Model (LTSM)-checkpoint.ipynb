{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Resources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=lV09_8432VA - Optimizing with TensorBoard - Deep Learning w/ Python, TensorFlow & Keras p.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -------------- Modelling Packages --------------\n",
    "# For modeling\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# Callback Functions\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# For Timestamping Models\n",
    "import time\n",
    "\n",
    "# -------------- General Packages --------------\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Saving Files\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the split dataset directory, return the train/test split\n",
    "def load_dataset(split_data_dir):\n",
    "    pickle_in = open(split_data_dir+'X_train.pickle','rb')\n",
    "    X_train = pickle.load(pickle_in)\n",
    "    \n",
    "    pickle_in = open(split_data_dir+'X_test.pickle','rb')\n",
    "    X_test = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(split_data_dir+'y_train.pickle','rb')\n",
    "    y_train = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(split_data_dir+'y_test.pickle','rb')\n",
    "    y_test = pickle.load(pickle_in)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def load_tokenizer(tokenizer_dir)\n",
    "    pickle_in = open(tokenizer_dir,'rb')\n",
    "    t = pickle.load(pickle_in)\n",
    "    return t\n",
    "    \n",
    "split_data_dir = './split_data/'\n",
    "X_train,X_test,y_train,y_test = load_dataset(split_data_dir)\n",
    "\n",
    "tokenizer_dir = '.tokenizer.pickle'\n",
    "t = load_tokenizer(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Tokenizer Values --------------\n",
    "SENTENCE_SIZE = 20\n",
    "\n",
    "# -------------- Layer Size Parameters --------------\n",
    "LSTM_SIZE = 50\n",
    "DENSE_SIZE = 20\n",
    "\n",
    "\n",
    "# -------------- DIRECTORIES --------------\n",
    "MODEL_DIR = './models/'\n",
    "NAME = 'FN-{}S-{}LSTM-{}D-{}.hdf5'.format(SENTENCE_SIZE,LSTM_SIZE,DENSE_SIZE,time.time())\n",
    "log_dir = os.path.join(\"logs\",NAME)\n",
    "\n",
    "\n",
    "# -------------- Compile Parameters --------------\n",
    "activation = 'softmax'\n",
    "optimizer = 'RMSProp'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# -------------- Callbacks --------------\n",
    "# access tensorboard from the command line: tensorboard --logdir logs/\n",
    "tensorboard = TensorBoard(log_dir=log_dir) \n",
    "checkpointer = ModelCheckpoint(MODEL_DIR+NAME, \n",
    "                               monitor='val_accuracy', \n",
    "                               verbose=1, \n",
    "                               save_best_only=True, \n",
    "                               mode='auto')\n",
    "callbacks=[tensorboard,checkpointer]\n",
    "\n",
    "\n",
    "# -------------- Fitting Parameters --------------\n",
    "epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_9.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: dense_9/BiasAdd:0\n",
      "  str(x.name))\n",
      "C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_10.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: dense_10/BiasAdd:0\n",
      "  str(x.name))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_6:0\", shape=(None, 20, 1), dtype=float32) at layer \"input_6\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1a1cb35666b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_dense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[1;32m--> 241\u001b[1;33m             self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m                                          \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m                                          \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1512\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_6:0\", shape=(None, 20, 1), dtype=float32) at layer \"input_6\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# FIRST MODEL: TITLE1_EN\n",
    "first_input = Input((SENTENCE_SIZE,1))\n",
    "first_LSTM = LSTM(LSTM_SIZE)(first_input)\n",
    "first_dense = Dense(DENSE_SIZE)(first_LSTM)\n",
    "\n",
    "# SECOND MODEL: TITLE2_EN\n",
    "second_input = Input((SENTENCE_SIZE,1))\n",
    "second_LSTM = LSTM(LSTM_SIZE)(second_input)\n",
    "second_dense = Dense(DENSE_SIZE)(second_LSTM)\n",
    "\n",
    "# MERGE MODEL\n",
    "merged = Concatenate(axis=1)([first_dense, second_dense])\n",
    "merged_dense = Dense(DENSE_SIZE)(merged)\n",
    "output_layer = Dense(3, activation='softmax')(merged_dense)\n",
    "\n",
    "model = Model(inputs=[first_input, second_input], outputs=output_layer)\n",
    "model.compile(optimizer=optimizer, loss=loss,metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14667 samples, validate on 5052 samples\n",
      "Epoch 1/100\n",
      "  512/14667 [>.............................] - ETA: 1:00 - loss: 1.3114 - accuracy: 0.3848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.293926). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14667/14667 [==============================] - 12s 835us/step - loss: 1.0771 - accuracy: 0.4085 - val_loss: 1.0515 - val_accuracy: 0.4349\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43488, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 2/100\n",
      "14667/14667 [==============================] - 11s 737us/step - loss: 1.0473 - accuracy: 0.4356 - val_loss: 1.0375 - val_accuracy: 0.4400\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.43488 to 0.44002, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 3/100\n",
      "14667/14667 [==============================] - 11s 737us/step - loss: 1.0373 - accuracy: 0.4439 - val_loss: 1.0438 - val_accuracy: 0.4319\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.44002\n",
      "Epoch 4/100\n",
      "14667/14667 [==============================] - 10s 706us/step - loss: 1.0303 - accuracy: 0.4473 - val_loss: 1.0385 - val_accuracy: 0.4489\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.44002 to 0.44893, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 5/100\n",
      "14667/14667 [==============================] - 9s 627us/step - loss: 1.0250 - accuracy: 0.4556 - val_loss: 1.0812 - val_accuracy: 0.4181\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.44893\n",
      "Epoch 6/100\n",
      "14667/14667 [==============================] - 9s 629us/step - loss: 1.0227 - accuracy: 0.4571 - val_loss: 1.0227 - val_accuracy: 0.4489\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.44893\n",
      "Epoch 7/100\n",
      "14667/14667 [==============================] - 9s 618us/step - loss: 1.0176 - accuracy: 0.4593 - val_loss: 1.0227 - val_accuracy: 0.4547\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.44893 to 0.45467, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 8/100\n",
      "14667/14667 [==============================] - 9s 624us/step - loss: 1.0159 - accuracy: 0.4621 - val_loss: 1.0125 - val_accuracy: 0.4677\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.45467 to 0.46774, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 9/100\n",
      "14667/14667 [==============================] - 9s 632us/step - loss: 1.0125 - accuracy: 0.4586 - val_loss: 1.0080 - val_accuracy: 0.4677\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.46774\n",
      "Epoch 10/100\n",
      "14667/14667 [==============================] - 9s 630us/step - loss: 1.0093 - accuracy: 0.4623 - val_loss: 1.0065 - val_accuracy: 0.4691\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.46774 to 0.46912, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 11/100\n",
      "14667/14667 [==============================] - 9s 622us/step - loss: 1.0072 - accuracy: 0.4623 - val_loss: 1.0087 - val_accuracy: 0.4695\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.46912 to 0.46952, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 12/100\n",
      "14667/14667 [==============================] - 9s 638us/step - loss: 1.0033 - accuracy: 0.4710 - val_loss: 1.0050 - val_accuracy: 0.4701\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.46952 to 0.47011, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 13/100\n",
      "14667/14667 [==============================] - 9s 635us/step - loss: 1.0011 - accuracy: 0.4716 - val_loss: 1.0032 - val_accuracy: 0.4642\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.47011\n",
      "Epoch 14/100\n",
      "14667/14667 [==============================] - 9s 620us/step - loss: 0.9981 - accuracy: 0.4755 - val_loss: 1.0134 - val_accuracy: 0.4604\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.47011\n",
      "Epoch 15/100\n",
      "14667/14667 [==============================] - 11s 757us/step - loss: 0.9960 - accuracy: 0.4762 - val_loss: 0.9924 - val_accuracy: 0.4788\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.47011 to 0.47882, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 16/100\n",
      "14667/14667 [==============================] - 10s 677us/step - loss: 0.9916 - accuracy: 0.4772 - val_loss: 0.9964 - val_accuracy: 0.4798\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.47882 to 0.47981, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 17/100\n",
      "14667/14667 [==============================] - 10s 692us/step - loss: 0.9910 - accuracy: 0.4792 - val_loss: 0.9941 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.47981\n",
      "Epoch 18/100\n",
      "14667/14667 [==============================] - 10s 701us/step - loss: 0.9872 - accuracy: 0.4853 - val_loss: 0.9910 - val_accuracy: 0.4816\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.47981 to 0.48159, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 19/100\n",
      "14667/14667 [==============================] - 9s 636us/step - loss: 0.9854 - accuracy: 0.4793 - val_loss: 0.9862 - val_accuracy: 0.4824\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.48159 to 0.48238, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 20/100\n",
      "14667/14667 [==============================] - 9s 628us/step - loss: 0.9815 - accuracy: 0.4858 - val_loss: 1.0704 - val_accuracy: 0.4236\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.48238\n",
      "Epoch 21/100\n",
      "14667/14667 [==============================] - 10s 649us/step - loss: 0.9792 - accuracy: 0.4871 - val_loss: 0.9840 - val_accuracy: 0.4760\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.48238\n",
      "Epoch 22/100\n",
      "14667/14667 [==============================] - 10s 658us/step - loss: 0.9759 - accuracy: 0.4861 - val_loss: 0.9978 - val_accuracy: 0.4733\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.48238\n",
      "Epoch 23/100\n",
      "14667/14667 [==============================] - 12s 843us/step - loss: 0.9755 - accuracy: 0.4932 - val_loss: 0.9901 - val_accuracy: 0.4802\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.48238\n",
      "Epoch 24/100\n",
      "14667/14667 [==============================] - 10s 690us/step - loss: 0.9716 - accuracy: 0.4940 - val_loss: 0.9846 - val_accuracy: 0.4826\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.48238 to 0.48258, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 25/100\n",
      "14667/14667 [==============================] - 10s 663us/step - loss: 0.9691 - accuracy: 0.4978 - val_loss: 0.9899 - val_accuracy: 0.4796\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.48258\n",
      "Epoch 26/100\n",
      "14667/14667 [==============================] - 9s 634us/step - loss: 0.9658 - accuracy: 0.5006 - val_loss: 0.9966 - val_accuracy: 0.4709\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.48258\n",
      "Epoch 27/100\n",
      "14667/14667 [==============================] - 9s 626us/step - loss: 0.9658 - accuracy: 0.4975 - val_loss: 0.9774 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.48258 to 0.48357, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 28/100\n",
      "14667/14667 [==============================] - 9s 627us/step - loss: 0.9646 - accuracy: 0.4979 - val_loss: 0.9815 - val_accuracy: 0.4897\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.48357 to 0.48971, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 29/100\n",
      "14667/14667 [==============================] - 9s 640us/step - loss: 0.9603 - accuracy: 0.5022 - val_loss: 0.9763 - val_accuracy: 0.4877\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.48971\n",
      "Epoch 30/100\n",
      "14667/14667 [==============================] - 9s 626us/step - loss: 0.9595 - accuracy: 0.5018 - val_loss: 0.9776 - val_accuracy: 0.4905\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.48971 to 0.49050, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 31/100\n",
      "14667/14667 [==============================] - 9s 634us/step - loss: 0.9547 - accuracy: 0.5042 - val_loss: 0.9901 - val_accuracy: 0.4826\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.49050\n",
      "Epoch 32/100\n",
      "14667/14667 [==============================] - 9s 642us/step - loss: 0.9562 - accuracy: 0.5060 - val_loss: 0.9858 - val_accuracy: 0.4840\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.49050\n",
      "Epoch 33/100\n",
      "14667/14667 [==============================] - 10s 669us/step - loss: 0.9523 - accuracy: 0.5086 - val_loss: 0.9821 - val_accuracy: 0.4917\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.49050 to 0.49169, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 34/100\n",
      "14667/14667 [==============================] - 10s 714us/step - loss: 0.9467 - accuracy: 0.5091 - val_loss: 0.9886 - val_accuracy: 0.4814\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.49169\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14667/14667 [==============================] - 11s 755us/step - loss: 0.9457 - accuracy: 0.5094 - val_loss: 0.9665 - val_accuracy: 0.4998\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.49169 to 0.49980, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 36/100\n",
      "14667/14667 [==============================] - 10s 655us/step - loss: 0.9421 - accuracy: 0.5172 - val_loss: 0.9713 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.49980\n",
      "Epoch 37/100\n",
      "14667/14667 [==============================] - 10s 705us/step - loss: 0.9415 - accuracy: 0.5176 - val_loss: 0.9687 - val_accuracy: 0.4994\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.49980\n",
      "Epoch 38/100\n",
      "14667/14667 [==============================] - 12s 788us/step - loss: 0.9388 - accuracy: 0.5165 - val_loss: 0.9648 - val_accuracy: 0.5012\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.49980 to 0.50119, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 39/100\n",
      "14667/14667 [==============================] - 10s 701us/step - loss: 0.9360 - accuracy: 0.5183 - val_loss: 0.9862 - val_accuracy: 0.4820\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.50119\n",
      "Epoch 40/100\n",
      "14667/14667 [==============================] - 11s 752us/step - loss: 0.9335 - accuracy: 0.5227 - val_loss: 0.9725 - val_accuracy: 0.4907\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.50119\n",
      "Epoch 41/100\n",
      "14667/14667 [==============================] - 11s 742us/step - loss: 0.9351 - accuracy: 0.5210 - val_loss: 0.9751 - val_accuracy: 0.4949\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.50119\n",
      "Epoch 42/100\n",
      "14667/14667 [==============================] - 11s 754us/step - loss: 0.9293 - accuracy: 0.5240 - val_loss: 0.9772 - val_accuracy: 0.4972\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.50119\n",
      "Epoch 43/100\n",
      "14667/14667 [==============================] - 10s 654us/step - loss: 0.9264 - accuracy: 0.5246 - val_loss: 0.9665 - val_accuracy: 0.4980\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.50119\n",
      "Epoch 44/100\n",
      "14667/14667 [==============================] - 10s 667us/step - loss: 0.9259 - accuracy: 0.5285 - val_loss: 0.9741 - val_accuracy: 0.5030\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.50119 to 0.50297, saving model to ./models/FN-20S-50LSTM-20D-1572893199.4300237.hdf5\n",
      "Epoch 45/100\n",
      "14667/14667 [==============================] - 9s 646us/step - loss: 0.9214 - accuracy: 0.5283 - val_loss: 0.9603 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.50297\n",
      "Epoch 46/100\n",
      "14667/14667 [==============================] - 9s 632us/step - loss: 0.9210 - accuracy: 0.5313 - val_loss: 0.9624 - val_accuracy: 0.5024\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.50297\n",
      "Epoch 47/100\n",
      "14667/14667 [==============================] - 10s 698us/step - loss: 0.9209 - accuracy: 0.5301 - val_loss: 0.9751 - val_accuracy: 0.4974\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.50297\n",
      "Epoch 48/100\n",
      "14667/14667 [==============================] - 10s 683us/step - loss: 0.9191 - accuracy: 0.5354 - val_loss: 0.9687 - val_accuracy: 0.4956\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.50297\n",
      "Epoch 49/100\n",
      "14667/14667 [==============================] - 9s 645us/step - loss: 0.9149 - accuracy: 0.5386 - val_loss: 0.9691 - val_accuracy: 0.4883\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.50297\n",
      "Epoch 50/100\n",
      "14667/14667 [==============================] - 10s 698us/step - loss: 0.9127 - accuracy: 0.5383 - val_loss: 0.9770 - val_accuracy: 0.4984\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.50297\n",
      "Epoch 51/100\n",
      "12928/14667 [=========================>....] - ETA: 0s - loss: 0.9080 - accuracy: 0.5360"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e69162a7f7d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mSENTENCE_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSENTENCE_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m           callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.dirname(MODEL_DIR), exist_ok=True)\n",
    "\n",
    "# Training the model\n",
    "model.fit([X_train[:,:SENTENCE_SIZE], X_train[:,SENTENCE_SIZE:]], y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=([X_test[:,:SENTENCE_SIZE], X_test[:,SENTENCE_SIZE:]], y_test),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = model.predict([X.iloc[0][:n].reshape(1,20,1),X[.loc[0][:n].reshape(1,20,1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
