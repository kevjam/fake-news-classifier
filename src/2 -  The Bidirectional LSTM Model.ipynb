{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-2e290b6ebd9c>\", line 6, in <module>\n",
      "    from keras.models import Model, Sequential\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 63, in <module>\n",
      "    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\framework_lib.py\", line 25, in <module>\n",
      "    from tensorflow.python.framework.ops import Graph\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 58, in <module>\n",
      "    from tensorflow.python.platform import app\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 23, in <module>\n",
      "    from absl.app import run as _run\n",
      "ModuleNotFoundError: No module named 'absl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 13, in <module>\n",
      "    from tensorflow.python.eager import execute as _execute\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 28, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 58, in <module>\n",
      "    from tensorflow.python.platform import app\n",
      "  File \"C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 23, in <module>\n",
      "    from absl.app import run as _run\n",
      "ModuleNotFoundError: No module named 'absl'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# For Saving/Loading Files\n",
    "from utils.storage import load_data,load_tokenizers\n",
    "\n",
    "# -------------- Modelling Packages --------------\n",
    "# For modeling\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, LSTM, Bidirectional\n",
    "from keras.layers import Input, Reshape, SpatialDropout1D, Dense, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras import optimizers\n",
    "\n",
    "# Callback Functions\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# For Timestamping Models\n",
    "import time\n",
    "\n",
    "# For balancing class weights\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# -------------- General Packages --------------\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Saving/Loading\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models/'\n",
    "SPLIT_DATA_DIR = './split_data/'\n",
    "LOG_DIR = 'logs'\n",
    "TOKENIZER_DIR = './tokenizers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset + Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_X_train,EN_X_test,ZH_X_train,ZH_X_test,y_train,y_test = load_data(SPLIT_DATA_DIR)\n",
    "t_EN,t_ZH = load_tokenizers(TOKENIZER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(MODEL_DIR), exist_ok=True)\n",
    "\n",
    "# -------------- Tokenizer Values --------------\n",
    "EN_SENTENCE_SIZE = int(EN_X_train.shape[1]/2)\n",
    "ZH_SENTENCE_SIZE = int(ZH_X_train.shape[1]/2)\n",
    "en_vocab_size = 35000\n",
    "zh_vocab_size = 70000\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "\n",
    "# -------------- TUNABLE HYPERPARAMETERS --------------\n",
    "EMBED_SIZES = [ 50 ]\n",
    "LSTM_SIZES = [ 100 ]\n",
    "LSTM_LAYER_SIZES = [ 1 ]\n",
    "DROPOUT_SIZES = [ (0.75,0.25) ]\n",
    "# DROPOUT_SIZES = [(0,0),(0.5,0),(0,0.5),(0.5,0.5),\n",
    "#                  (0.25,0.25),(0.25,0.5),(0.5,0.25),(0.25,0),\n",
    "#                  (0,0.25),(0.75,0.75),(0.75,0.5),(0.5,0.75),\n",
    "#                  (0.75,0),(0,0.75),(0.75,0.25),(0.25,0.75)]\n",
    "\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "optimizer = optimizers.adam()\n",
    "#optimizer = optimizers.sgd(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192223 samples, validate on 64087 samples\n",
      "Epoch 1/200\n",
      "192223/192223 [==============================] - 58s 303us/step - loss: 0.6005 - accuracy: 0.7369 - val_loss: 0.4210 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81421, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 2/200\n",
      "192223/192223 [==============================] - 51s 267us/step - loss: 0.3919 - accuracy: 0.8266 - val_loss: 0.3713 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81421 to 0.83824, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 3/200\n",
      "192223/192223 [==============================] - 51s 266us/step - loss: 0.3324 - accuracy: 0.8567 - val_loss: 0.3557 - val_accuracy: 0.8495\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83824 to 0.84952, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 4/200\n",
      "192223/192223 [==============================] - 51s 268us/step - loss: 0.2969 - accuracy: 0.8726 - val_loss: 0.3488 - val_accuracy: 0.8548\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84952 to 0.85484, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 5/200\n",
      "192223/192223 [==============================] - 52s 268us/step - loss: 0.2699 - accuracy: 0.8863 - val_loss: 0.3515 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.85484 to 0.85624, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 6/200\n",
      "192223/192223 [==============================] - 51s 266us/step - loss: 0.2507 - accuracy: 0.8947 - val_loss: 0.3487 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.85624 to 0.85924, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 7/200\n",
      "192223/192223 [==============================] - 51s 268us/step - loss: 0.2339 - accuracy: 0.9031 - val_loss: 0.3535 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.85924\n",
      "Epoch 8/200\n",
      "192223/192223 [==============================] - 51s 267us/step - loss: 0.2206 - accuracy: 0.9078 - val_loss: 0.3550 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.85924 to 0.86078, saving model to ./models/BiLSTM-50E-1x100L-(0.75, 0.25)Dropout-1574663940.6780815.hdf5\n",
      "Epoch 9/200\n",
      "192223/192223 [==============================] - 51s 267us/step - loss: 0.2070 - accuracy: 0.9138 - val_loss: 0.3624 - val_accuracy: 0.8576\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86078\n"
     ]
    }
   ],
   "source": [
    "for EMBED_SIZE in EMBED_SIZES:\n",
    "    for DROPOUT_SIZE in DROPOUT_SIZES:\n",
    "        for LSTM_SIZE in LSTM_SIZES:\n",
    "            for LSTM_LAYERS in LSTM_LAYER_SIZES:\n",
    "                \n",
    "                # -------------- MODEL NAMING --------------\n",
    "                NAME = 'BiLSTM-{}E-{}x{}L-{}Dropout-{}.hdf5'.format(EMBED_SIZE,\n",
    "                                                                         LSTM_LAYERS,LSTM_SIZE,\n",
    "                                                                         DROPOUT_SIZE,\n",
    "                                                                         time.time())\n",
    "                print('Creating {}'.format(NAME))\n",
    "                MODEL_LOG_DIR = os.path.join(LOG_DIR,NAME)\n",
    "\n",
    "                # -------------- Callbacks --------------\n",
    "                # access tensorboard from the command line: tensorboard --logdir=logs/\n",
    "                tensorboard = TensorBoard(log_dir=MODEL_LOG_DIR) \n",
    "                checkpointer = ModelCheckpoint(MODEL_DIR+NAME, \n",
    "                                               monitor='val_accuracy', \n",
    "                                               verbose=1, \n",
    "                                               save_best_only=True, \n",
    "                                               mode='auto')\n",
    "                earlystop = EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "\n",
    "                callbacks=[tensorboard,checkpointer,earlystop]\n",
    "\n",
    "                # -------------- EN MODEL CREATION --------------\n",
    "                EN_INPUT = Input(shape=(EN_SENTENCE_SIZE*2,))\n",
    "                EN_MODEL = Reshape((-1,2,EN_SENTENCE_SIZE))(EN_INPUT)\n",
    "                EN_MODEL = Embedding(en_vocab_size,\n",
    "                                EMBED_SIZE,\n",
    "                                input_shape=(2,EN_SENTENCE_SIZE),\n",
    "                                trainable=True)(EN_MODEL)\n",
    "                EN_MODEL = Reshape((2,EN_SENTENCE_SIZE*EMBED_SIZE,))(EN_MODEL)\n",
    "                \n",
    "                if DROPOUT_SIZE[0] > 0: EN_MODEL = SpatialDropout1D(DROPOUT_SIZE[0])(EN_MODEL)\n",
    "                for layer in range(LSTM_LAYERS-1):\n",
    "                    EN_MODEL = Bidirectional(LSTM(LSTM_SIZE,\n",
    "                                                  return_sequences=True, \n",
    "                                                  recurrent_dropout=DROPOUT_SIZE[1]))(EN_MODEL)\n",
    "                EN_MODEL = Bidirectional(LSTM(LSTM_SIZE,\n",
    "                                              return_sequences=True,\n",
    "                                              recurrent_dropout=DROPOUT_SIZE[1]))(EN_MODEL)\n",
    "    \n",
    "                # -------------- ZH MODEL CREATION --------------\n",
    "                ZH_INPUT = Input(shape=(ZH_SENTENCE_SIZE*2,))\n",
    "                ZH_MODEL = Reshape((-1,2,ZH_SENTENCE_SIZE))(ZH_INPUT)\n",
    "                ZH_MODEL = Embedding(zh_vocab_size,\n",
    "                                EMBED_SIZE,\n",
    "                                input_shape=(2,ZH_SENTENCE_SIZE),\n",
    "                                trainable=True)(ZH_MODEL)\n",
    "                ZH_MODEL = Reshape((2,ZH_SENTENCE_SIZE*EMBED_SIZE,))(ZH_MODEL)\n",
    "                \n",
    "                if DROPOUT_SIZE[0] > 0: ZH_MODEL = SpatialDropout1D(DROPOUT_SIZE[0])(ZH_MODEL)\n",
    "                for layer in range(LSTM_LAYERS-1):\n",
    "                    ZH_MODEL = Bidirectional(LSTM(LSTM_SIZE,\n",
    "                                                  return_sequences=True, \n",
    "                                                  recurrent_dropout=DROPOUT_SIZE[1]))(ZH_MODEL)\n",
    "                ZH_MODEL = Bidirectional(LSTM(LSTM_SIZE,\n",
    "                                              return_sequences=True,\n",
    "                                              recurrent_dropout=DROPOUT_SIZE[1]))(ZH_MODEL)\n",
    "                    \n",
    "                # -------------- MERGE MODEL --------------\n",
    "                merged = Concatenate(1)([EN_MODEL,ZH_MODEL])\n",
    "                merged = LSTM(LSTM_SIZE,\n",
    "                              return_sequences=True,\n",
    "                              recurrent_dropout=DROPOUT_SIZE[1])(merged)\n",
    "                merged = Flatten()(merged)\n",
    "                merged = Dense(3, activation='softmax')(merged)\n",
    "\n",
    "                model = Model(inputs=[EN_INPUT,ZH_INPUT], outputs=merged)\n",
    "                model.compile(optimizer=optimizer, loss=loss,metrics=metrics)\n",
    "\n",
    "                # -------------- Training the model --------------\n",
    "                model.fit([EN_X_train,ZH_X_train], y_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data=([EN_X_test,ZH_X_test], y_test),\n",
    "                          callbacks=callbacks,\n",
    "                          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
