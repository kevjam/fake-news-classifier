{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://keras.io/preprocessing/text/\n",
    "- https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n",
    "- https://www.youtube.com/watch?v=j-3vuBynnOE - Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2\n",
    "\n",
    "- http://faroit.com/keras-docs/1.2.2/preprocessing/text/#tokenizer\n",
    "\n",
    "- https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -------------- Preprocessing Packages --------------\n",
    "# For tokenizing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------- General Packages --------------\n",
    "# General Use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Saving Files\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters corrupted, unusable/unused data from the dataset\n",
    "def filter_dataset(df):\n",
    "    df = df.drop(columns=['id','tid1','tid2']) # drop id columns\n",
    "    df = df.drop(columns=['title1_zh','title2_zh']) # drop chinese columns\n",
    "\n",
    "    # Remove symbols\n",
    "    df['title1_en'] = df['title1_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "    df['title2_en'] = df['title2_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "\n",
    "    # Replace empty strings with NaN values\n",
    "    df['title1_en'].replace('', np.nan, inplace=True)\n",
    "    df['title2_en'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    # Remove rows with no label\n",
    "    labels = ['unrelated','agreed','disagreed']\n",
    "    df = df[df.label.isin(labels)]\n",
    "    \n",
    "    # Remove Unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Drop rows with null values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Returns a datset with an equal sampling of each label\n",
    "def equalize_dataset_labels(df, seed=1):\n",
    "    # Get minimum label count\n",
    "    n = df.label.value_counts().min()\n",
    "    \n",
    "    # Grabbing equal amounts of training data from each class\n",
    "    dfa = df[df['label']=='unrelated'].sample(n,random_state=seed)\n",
    "    dfb = df[df['label']=='agreed'].sample(n,random_state=seed)\n",
    "    dfc = df[df['label']=='disagreed'].sample(n,random_state=seed)\n",
    "    \n",
    "    # Recombine dataset and shuffle\n",
    "    df = pd.concat([dfa,dfb,dfc])\n",
    "    df = df.sample(frac=1,random_state=seed)\n",
    "    return df\n",
    "\n",
    "# Convert labels to integers for predictions\n",
    "def encode_labels(df):\n",
    "    # encoding the labels\n",
    "    labels = {'unrelated':0,'agreed':1,'disagreed':2}\n",
    "    df['label'].replace(labels,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word tokenizer given dataframe(s)\n",
    "def create_tokenizer(*data, num_words=None, lower=True, split=' ', oov_token=None, filename='tokenizer'):\n",
    "    # create the tokenizer\n",
    "    t = Tokenizer(num_words=num_words, lower=lower, split=split, oov_token=oov_token)\n",
    "    \n",
    "    # fit tokenizer\n",
    "    for df in data:\n",
    "        t.fit_on_texts(df['title1_en'])  \n",
    "        t.fit_on_texts(df['title2_en'])  \n",
    "    \n",
    "    # save for future use\n",
    "    pickle_out = open(filename+'.pickle', 'wb')\n",
    "    pickle.dump(t,pickle_out)\n",
    "    pickle_out.close()\n",
    "    return t\n",
    "\n",
    "# Tokenizes titles and encodes labels, trains a word tokenizer that is saved to a file\n",
    "def tokenize(t, df, maxlen=20):\n",
    "    # fit the tokenizer on the documents  \n",
    "    data1 = pad_sequences(sequences=t.texts_to_sequences(df['title1_en']), maxlen=maxlen)\n",
    "    data2 = pad_sequences(sequences=t.texts_to_sequences(df['title2_en']), maxlen=maxlen)\n",
    "    \n",
    "    # recombine\n",
    "    df = pd.DataFrame(np.concatenate((data1,data2),axis=1)).join(df['label'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Preprocessed/Tokenized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given train and test data, split into features and labels and save\n",
    "def save_data(train, test, maxlen=20, save_dir='./split_data/'):\n",
    "    # Split the data into X and y\n",
    "    X_train = train.iloc[:,:maxlen*2].to_numpy()\n",
    "    X_test = test.iloc[:,:maxlen*2].to_numpy()\n",
    "    y_train = train['label'].to_numpy()\n",
    "    y_test = test['label'].to_numpy()\n",
    "    \n",
    "    split_data_dir=save_dir\n",
    "    os.makedirs(os.path.dirname(split_data_dir), exist_ok=True)\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(split_data_dir+'y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test,pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7026: expected 8 fields, saw 9\\nSkipping line 44341: expected 8 fields, saw 9\\nSkipping line 58784: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 99101: expected 8 fields, saw 10\\nSkipping line 104716: expected 8 fields, saw 9\\nSkipping line 127866: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 140436: expected 8 fields, saw 9\\nSkipping line 152888: expected 8 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "input_train = './data/train.csv'\n",
    "input_validation = './data/validation.csv'\n",
    "\n",
    "df_train = pd.read_csv(input_train,encoding='utf-8-sig',error_bad_lines=False)\n",
    "df_test = pd.read_csv(input_validation,encoding='utf-8-sig',error_bad_lines=False)\n",
    "\n",
    "df_train = filter_dataset(df_train)\n",
    "df_test = filter_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_tokenizer(df_train, num_words=40000, oov_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_equalized = equalize_dataset_labels(df_train)\n",
    "# df_test_equalized = equalize_dataset_labels(df_test)\n",
    "\n",
    "df_train_encoded = encode_labels(df_train)\n",
    "df_test_encoded = encode_labels(df_test)\n",
    "\n",
    "df_train_tokenized = tokenize(t,df_train_encoded,25)\n",
    "df_test_tokenized = tokenize(t,df_test_encoded,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train=df_train_tokenized,\n",
    "          test=df_test_tokenized,\n",
    "          maxlen=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Tokenization\n",
    "\n",
    "Some experimentation with inverse tokenizing to double check if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some people say that cabbage is the king of poison in vegetables can you still']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sequences_to_texts([df_train_tokenized.iloc[0,:25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maradona talks about health im better than ever dont listen to rumour']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sequences_to_texts([df_train_tokenized.iloc[0,25:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tokenized.iloc[0,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Some people say that cabbage is the king of po...</td>\n",
       "      <td>Maradona talks about health Im better than eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          title1_en  \\\n",
       "0      0  Some people say that cabbage is the king of po...   \n",
       "\n",
       "                                           title2_en  label  \n",
       "0  Maradona talks about health Im better than eve...      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some people say that cabbage is the king of po...</td>\n",
       "      <td>Maradona talks about health Im better than eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secretly the pharmacy has a cheap cream put on...</td>\n",
       "      <td>Dont be a fool to get the bags under your eyes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just at 23 28 the Chinese stock market broke a...</td>\n",
       "      <td>China stock market startling news the words of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the most powerful legion in World War ...</td>\n",
       "      <td>The three great rumblings of the Second World ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Discovery of Miracles of Medical Miracles The ...</td>\n",
       "      <td>Why is red wine fighting cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title1_en  \\\n",
       "0  Some people say that cabbage is the king of po...   \n",
       "1  Secretly the pharmacy has a cheap cream put on...   \n",
       "2  Just at 23 28 the Chinese stock market broke a...   \n",
       "3  Who was the most powerful legion in World War ...   \n",
       "4  Discovery of Miracles of Medical Miracles The ...   \n",
       "\n",
       "                                           title2_en  label  \n",
       "0  Maradona talks about health Im better than eve...      0  \n",
       "1  Dont be a fool to get the bags under your eyes...      1  \n",
       "2  China stock market startling news the words of...      0  \n",
       "3  The three great rumblings of the Second World ...      0  \n",
       "4                    Why is red wine fighting cancer      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
