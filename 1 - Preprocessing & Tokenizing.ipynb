{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -------------- Preprocessing Packages --------------\n",
    "# For tokenizing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------- General Packages --------------\n",
    "# General Use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Saving Files\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters corrupted, unusable/unused data from the dataset\n",
    "def filter_dataset(df):\n",
    "    df = df.drop(columns=['id','tid1','tid2']) # drop id columns\n",
    "    df = df.drop(columns=['title1_zh','title2_zh']) # drop chinese columns\n",
    "\n",
    "    # Remove symbols\n",
    "    df['title1_en'] = df['title1_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "    df['title2_en'] = df['title2_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "\n",
    "    # Replace empty strings with NaN values\n",
    "    df['title1_en'].replace('', np.nan, inplace=True)\n",
    "    df['title2_en'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    # Remove rows with no label\n",
    "    labels = ['unrelated','agreed','disagreed']\n",
    "    df = df[df.label.isin(labels)]\n",
    "    \n",
    "    # Remove Unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Drop rows with null values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Returns a datset with an equal sampling of each label\n",
    "def equalize_dataset_labels(df, seed=1):\n",
    "    # Get minimum label count\n",
    "    n = df.label.value_counts().min()\n",
    "    \n",
    "    # Grabbing equal amounts of training data from each class\n",
    "    dfa = df[df['label']=='unrelated'].sample(n,random_state=seed)\n",
    "    dfb = df[df['label']=='agreed'].sample(n,random_state=seed)\n",
    "    dfc = df[df['label']=='disagreed'].sample(n,random_state=seed)\n",
    "    \n",
    "    # Recombine dataset and shuffle\n",
    "    df = pd.concat([dfa,dfb,dfc])\n",
    "    df = df.sample(frac=1,random_state=seed)\n",
    "    return df\n",
    "\n",
    "# Convert labels to integers for predictions\n",
    "def encode_labels(df):\n",
    "    # encoding the labels\n",
    "    labels = {'unrelated':0,'agreed':1,'disagreed':2}\n",
    "    df['label'].replace(labels,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word tokenizer given dataframe(s)\n",
    "def create_tokenizer(*data, split=' ', filename='tokenizer'):\n",
    "    # create the tokenizer\n",
    "    t = Tokenizer(oov_token=True, split=split)\n",
    "    \n",
    "    # fit tokenizer\n",
    "    for df in data:\n",
    "        t.fit_on_texts(df['title1_en'])  \n",
    "        t.fit_on_texts(df['title2_en'])  \n",
    "    \n",
    "    # save for future use\n",
    "    pickle_out = open(filename+'.pickle', 'wb')\n",
    "    pickle.dump(t,pickle_out)\n",
    "    pickle_out.close()\n",
    "    return t\n",
    "\n",
    "# Tokenizes titles and encodes labels, trains a word tokenizer that is saved to a file\n",
    "def tokenize(t, df, maxlen=20):\n",
    "    # fit the tokenizer on the documents  \n",
    "    data1 = pad_sequences(sequences=t.texts_to_sequences(df['title1_en']), maxlen=maxlen)\n",
    "    data2 = pad_sequences(sequences=t.texts_to_sequences(df['title2_en']), maxlen=maxlen)\n",
    "    \n",
    "    # recombine\n",
    "    df = pd.DataFrame(np.concatenate((data1,data2),axis=1)).join(df['label'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given train and test data, split into features and labels and save\n",
    "def save_data(train, test, maxlen=20, save_dir='./split_data/'):\n",
    "    # Split the data into X and y\n",
    "    X_train = train.iloc[:,:maxlen*2].to_numpy()\n",
    "    X_test = test.iloc[:,:maxlen*2].to_numpy()\n",
    "    y_train = train['label'].to_numpy()\n",
    "    y_test = test['label'].to_numpy()\n",
    "\n",
    "    # reshape the X train data for use\n",
    "    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "    \n",
    "    split_data_dir=save_dir\n",
    "    os.makedirs(os.path.dirname(split_data_dir), exist_ok=True)\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(split_data_dir+'y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test,pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7026: expected 8 fields, saw 9\\nSkipping line 44341: expected 8 fields, saw 9\\nSkipping line 58784: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 99101: expected 8 fields, saw 10\\nSkipping line 104716: expected 8 fields, saw 9\\nSkipping line 127866: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 140436: expected 8 fields, saw 9\\nSkipping line 152888: expected 8 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "input_train = './data/train.csv'\n",
    "input_validation = './data/validation.csv'\n",
    "\n",
    "df_train = pd.read_csv(input_train,encoding='utf-8-sig',error_bad_lines=False)\n",
    "df_test = pd.read_csv(input_validation,encoding='utf-8-sig',error_bad_lines=False)\n",
    "\n",
    "df_train = filter_dataset(df_train)\n",
    "df_test = filter_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_tokenizer(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = equalize_dataset_labels(df_train)\n",
    "df_test = equalize_dataset_labels(df_test)\n",
    "\n",
    "df_train = encode_labels(df_train)\n",
    "df_test = encode_labels(df_test)\n",
    "\n",
    "df_train = tokenize(t,df_train,20)\n",
    "df_test = tokenize(t,df_test,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train=df_train,test=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: 1,\n",
       " 'the': 2,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'is': 6,\n",
       " 'and': 7,\n",
       " 'in': 8,\n",
       " 'you': 9,\n",
       " 'not': 10,\n",
       " 'it': 11,\n",
       " 'be': 12,\n",
       " 'for': 13,\n",
       " 'can': 14,\n",
       " 'will': 15,\n",
       " 'with': 16,\n",
       " 'has': 17,\n",
       " 'are': 18,\n",
       " 'this': 19,\n",
       " 'that': 20,\n",
       " 'have': 21,\n",
       " 'do': 22,\n",
       " 'on': 23,\n",
       " 'was': 24,\n",
       " 'rumors': 25,\n",
       " 'these': 26,\n",
       " 'eat': 27,\n",
       " 'new': 28,\n",
       " 'rumor': 29,\n",
       " 'no': 30,\n",
       " 'people': 31,\n",
       " 'years': 32,\n",
       " 'by': 33,\n",
       " 'how': 34,\n",
       " 'at': 35,\n",
       " 'been': 36,\n",
       " 'your': 37,\n",
       " 'its': 38,\n",
       " 'days': 39,\n",
       " 'one': 40,\n",
       " 'three': 41,\n",
       " 'dont': 42,\n",
       " 'more': 43,\n",
       " 'i': 44,\n",
       " 'from': 45,\n",
       " 'after': 46,\n",
       " 'out': 47,\n",
       " 'li': 48,\n",
       " 'up': 49,\n",
       " 'hair': 50,\n",
       " 'weight': 51,\n",
       " 'but': 52,\n",
       " 'white': 53,\n",
       " 'his': 54,\n",
       " 'wang': 55,\n",
       " 'all': 56,\n",
       " 'as': 57,\n",
       " 'get': 58,\n",
       " 'two': 59,\n",
       " 'what': 60,\n",
       " 'her': 61,\n",
       " 'good': 62,\n",
       " 'cancer': 63,\n",
       " 'who': 64,\n",
       " 'old': 65,\n",
       " 'he': 66,\n",
       " 'only': 67,\n",
       " 'police': 68,\n",
       " 'zhang': 69,\n",
       " 'about': 70,\n",
       " 'an': 71,\n",
       " 'day': 72,\n",
       " 'blood': 73,\n",
       " 'than': 74,\n",
       " 'yang': 75,\n",
       " '2018': 76,\n",
       " 's': 77,\n",
       " 'love': 78,\n",
       " 'so': 79,\n",
       " 'rumour': 80,\n",
       " 'know': 81,\n",
       " 'yuan': 82,\n",
       " '3': 83,\n",
       " 'man': 84,\n",
       " 'big': 85,\n",
       " 'first': 86,\n",
       " 'year': 87,\n",
       " 'rural': 88,\n",
       " 'phone': 89,\n",
       " 'also': 90,\n",
       " 'there': 91,\n",
       " 'million': 92,\n",
       " 'liu': 93,\n",
       " 'chinese': 94,\n",
       " 'food': 95,\n",
       " '10': 96,\n",
       " 'she': 97,\n",
       " 'really': 98,\n",
       " 'pregnant': 99,\n",
       " 'most': 100,\n",
       " 'black': 101,\n",
       " 'lose': 102,\n",
       " 'child': 103,\n",
       " 'drink': 104,\n",
       " 'farmers': 105,\n",
       " 'when': 106,\n",
       " 'see': 107,\n",
       " 'water': 108,\n",
       " 'time': 109,\n",
       " 'like': 110,\n",
       " 'said': 111,\n",
       " 'pay': 112,\n",
       " 'still': 113,\n",
       " 'too': 114,\n",
       " 'if': 115,\n",
       " 'make': 116,\n",
       " 'many': 117,\n",
       " 'again': 118,\n",
       " 'way': 119,\n",
       " 'car': 120,\n",
       " 'money': 121,\n",
       " 'netizens': 122,\n",
       " 'does': 123,\n",
       " 'face': 124,\n",
       " 'eating': 125,\n",
       " '5': 126,\n",
       " 'baby': 127,\n",
       " 'why': 128,\n",
       " 'children': 129,\n",
       " 'they': 130,\n",
       " 'china': 131,\n",
       " 'very': 132,\n",
       " '1': 133,\n",
       " 'go': 134,\n",
       " 'use': 135,\n",
       " 'news': 136,\n",
       " 'every': 137,\n",
       " 'four': 138,\n",
       " 'married': 139,\n",
       " 'or': 140,\n",
       " 'woman': 141,\n",
       " 'loss': 142,\n",
       " 'fan': 143,\n",
       " 'countryside': 144,\n",
       " '2': 145,\n",
       " 'little': 146,\n",
       " 'zhao': 147,\n",
       " 'chen': 148,\n",
       " 'want': 149,\n",
       " 'wu': 150,\n",
       " 'take': 151,\n",
       " 'kinds': 152,\n",
       " 'skin': 153,\n",
       " 'medicine': 154,\n",
       " 'look': 155,\n",
       " 'ma': 156,\n",
       " 'should': 157,\n",
       " 'city': 158,\n",
       " 'song': 159,\n",
       " 'did': 160,\n",
       " 'home': 161,\n",
       " 'women': 162,\n",
       " 'cant': 163,\n",
       " 'buy': 164,\n",
       " 'night': 165,\n",
       " 'teach': 166,\n",
       " 'high': 167,\n",
       " 'down': 168,\n",
       " 'five': 169,\n",
       " 'him': 170,\n",
       " 'wife': 171,\n",
       " 'few': 172,\n",
       " 'fat': 173,\n",
       " 'before': 174,\n",
       " 'circle': 175,\n",
       " 'netizen': 176,\n",
       " 'them': 177,\n",
       " 'now': 178,\n",
       " 'just': 179,\n",
       " 'back': 180,\n",
       " 'exposure': 181,\n",
       " 'into': 182,\n",
       " 'divorce': 183,\n",
       " 'body': 184,\n",
       " 'their': 185,\n",
       " 'because': 186,\n",
       " 'exposed': 187,\n",
       " 'girl': 188,\n",
       " 'marriage': 189,\n",
       " 'ten': 190,\n",
       " 'may': 191,\n",
       " 'family': 192,\n",
       " 'birth': 193,\n",
       " 'finally': 194,\n",
       " 'come': 195,\n",
       " 'pregnancy': 196,\n",
       " 'cure': 197,\n",
       " 'life': 198,\n",
       " 'second': 199,\n",
       " 'zhu': 200,\n",
       " 'market': 201,\n",
       " 'friends': 202,\n",
       " 'easy': 203,\n",
       " 'believe': 204,\n",
       " 'effect': 205,\n",
       " 'boy': 206,\n",
       " 'daughter': 207,\n",
       " 'truth': 208,\n",
       " 'attention': 209,\n",
       " 'entertainment': 210,\n",
       " 'next': 211,\n",
       " 'tea': 212,\n",
       " 'much': 213,\n",
       " '7': 214,\n",
       " 'my': 215,\n",
       " 'son': 216,\n",
       " 'net': 217,\n",
       " 'plastic': 218,\n",
       " 'going': 219,\n",
       " 'house': 220,\n",
       " 'belly': 221,\n",
       " 'which': 222,\n",
       " 'small': 223,\n",
       " 'real': 224,\n",
       " 'month': 225,\n",
       " 'true': 226,\n",
       " 'quickly': 227,\n",
       " 'public': 228,\n",
       " 'long': 229,\n",
       " 'mother': 230,\n",
       " 'pressure': 231,\n",
       " 'six': 232,\n",
       " 'waist': 233,\n",
       " '20': 234,\n",
       " 'lost': 235,\n",
       " 'must': 236,\n",
       " 'death': 237,\n",
       " 'response': 238,\n",
       " 'times': 239,\n",
       " 'false': 240,\n",
       " 'cause': 241,\n",
       " 'video': 242,\n",
       " 'red': 243,\n",
       " 'official': 244,\n",
       " 'off': 245,\n",
       " 'price': 246,\n",
       " 'were': 247,\n",
       " 'suspected': 248,\n",
       " 'driving': 249,\n",
       " 'method': 250,\n",
       " 'drinking': 251,\n",
       " 'health': 252,\n",
       " '100': 253,\n",
       " 'together': 254,\n",
       " 'say': 255,\n",
       " 'need': 256,\n",
       " 'worth': 257,\n",
       " 'husband': 258,\n",
       " 'thin': 259,\n",
       " 'tse': 260,\n",
       " 'license': 261,\n",
       " 'dye': 262,\n",
       " 'bingbing': 263,\n",
       " 'never': 264,\n",
       " 'sugar': 265,\n",
       " 'being': 266,\n",
       " 'world': 267,\n",
       " 'fake': 268,\n",
       " 'catties': 269,\n",
       " 'let': 270,\n",
       " 'had': 271,\n",
       " 'internet': 272,\n",
       " 'subsidy': 273,\n",
       " 'traffic': 274,\n",
       " 'mobile': 275,\n",
       " 'power': 276,\n",
       " '4': 277,\n",
       " 'over': 278,\n",
       " 'announced': 279,\n",
       " 'men': 280,\n",
       " 'national': 281,\n",
       " 'property': 282,\n",
       " 'virus': 283,\n",
       " 'cup': 284,\n",
       " 'wants': 285,\n",
       " 'without': 286,\n",
       " 'school': 287,\n",
       " 'bad': 288,\n",
       " 'away': 289,\n",
       " 'summer': 290,\n",
       " 'once': 291,\n",
       " 'cold': 292,\n",
       " 'lin': 293,\n",
       " '6': 294,\n",
       " 'kind': 295,\n",
       " 'parents': 296,\n",
       " 'wash': 297,\n",
       " 'secret': 298,\n",
       " 'card': 299,\n",
       " 'subsidies': 300,\n",
       " 'stock': 301,\n",
       " 'made': 302,\n",
       " 'end': 303,\n",
       " 'minutes': 304,\n",
       " 'used': 305,\n",
       " 'bed': 306,\n",
       " '15': 307,\n",
       " '8': 308,\n",
       " 'open': 309,\n",
       " 'change': 310,\n",
       " 'village': 311,\n",
       " 'longer': 312,\n",
       " 'stomach': 313,\n",
       " 'ginger': 314,\n",
       " 'fruit': 315,\n",
       " 'age': 316,\n",
       " 'person': 317,\n",
       " 'things': 318,\n",
       " 'seven': 319,\n",
       " 'head': 320,\n",
       " 'pain': 321,\n",
       " 'best': 322,\n",
       " 'some': 323,\n",
       " 'fans': 324,\n",
       " 'female': 325,\n",
       " 'experts': 326,\n",
       " '30': 327,\n",
       " 'week': 328,\n",
       " 'network': 329,\n",
       " 'another': 330,\n",
       " 'cell': 331,\n",
       " 'turn': 332,\n",
       " 'test': 333,\n",
       " 'jin': 334,\n",
       " 'even': 335,\n",
       " 'thousand': 336,\n",
       " 'we': 337,\n",
       " 'diet': 338,\n",
       " 'pounds': 339,\n",
       " 'give': 340,\n",
       " 'months': 341,\n",
       " 'half': 342,\n",
       " 'country': 343,\n",
       " 'rumours': 344,\n",
       " 'tell': 345,\n",
       " 'free': 346,\n",
       " 'billion': 347,\n",
       " 'spread': 348,\n",
       " 'dollars': 349,\n",
       " 'found': 350,\n",
       " 'help': 351,\n",
       " 'me': 352,\n",
       " 'beauty': 353,\n",
       " '2017': 354,\n",
       " 'feng': 355,\n",
       " 'housing': 356,\n",
       " 'wedding': 357,\n",
       " 'fei': 358,\n",
       " 'number': 359,\n",
       " 'whole': 360,\n",
       " 'break': 361,\n",
       " 'us': 362,\n",
       " 'xiaolu': 363,\n",
       " 'rich': 364,\n",
       " 'beijing': 365,\n",
       " 'disease': 366,\n",
       " 'cctv': 367,\n",
       " 'land': 368,\n",
       " 'spring': 369,\n",
       " 'zhou': 370,\n",
       " 'stop': 371,\n",
       " 'often': 372,\n",
       " 'become': 373,\n",
       " 'other': 374,\n",
       " 'better': 375,\n",
       " 'less': 376,\n",
       " 'fast': 377,\n",
       " 'put': 378,\n",
       " 'vinegar': 379,\n",
       " 'sleep': 380,\n",
       " 'live': 381,\n",
       " 'points': 382,\n",
       " 'security': 383,\n",
       " 'says': 384,\n",
       " 'afraid': 385,\n",
       " 'fire': 386,\n",
       " 'han': 387,\n",
       " 'oil': 388,\n",
       " 'cars': 389,\n",
       " 'great': 390,\n",
       " 'died': 391,\n",
       " 'hot': 392,\n",
       " 'fight': 393,\n",
       " 'such': 394,\n",
       " 'chinas': 395,\n",
       " 'reason': 396,\n",
       " 'beautiful': 397,\n",
       " 'father': 398,\n",
       " 'rice': 399,\n",
       " 'latest': 400,\n",
       " 'information': 401,\n",
       " 'here': 402,\n",
       " 'effective': 403,\n",
       " 'got': 404,\n",
       " 'garlic': 405,\n",
       " 'hospital': 406,\n",
       " 'last': 407,\n",
       " 'relationship': 408,\n",
       " 'cash': 409,\n",
       " 'would': 410,\n",
       " 'team': 411,\n",
       " 'quit': 412,\n",
       " 'treatment': 413,\n",
       " 'eight': 414,\n",
       " 'students': 415,\n",
       " 'top': 416,\n",
       " 'girlfriend': 417,\n",
       " 'marry': 418,\n",
       " 'diabetes': 419,\n",
       " 'policy': 420,\n",
       " 'worry': 421,\n",
       " 'jia': 422,\n",
       " 'strong': 423,\n",
       " 'apple': 424,\n",
       " 'ufo': 425,\n",
       " 'natural': 426,\n",
       " 'simple': 427,\n",
       " 'united': 428,\n",
       " 'areas': 429,\n",
       " 'male': 430,\n",
       " 'recent': 431,\n",
       " 'lot': 432,\n",
       " 'clean': 433,\n",
       " 'yan': 434,\n",
       " 'air': 435,\n",
       " 'industry': 436,\n",
       " 'festival': 437,\n",
       " 'foods': 438,\n",
       " 'theres': 439,\n",
       " '50': 440,\n",
       " 'rid': 441,\n",
       " 'affair': 442,\n",
       " 'wei': 443,\n",
       " 'during': 444,\n",
       " 'learn': 445,\n",
       " 'milk': 446,\n",
       " 'hard': 447,\n",
       " 'think': 448,\n",
       " 'constipation': 449,\n",
       " 'sweet': 450,\n",
       " 'collection': 451,\n",
       " 'add': 452,\n",
       " 'states': 453,\n",
       " 'poison': 454,\n",
       " 'getting': 455,\n",
       " 'tears': 456,\n",
       " '000': 457,\n",
       " 'liying': 458,\n",
       " 'value': 459,\n",
       " 'regulations': 460,\n",
       " 'wine': 461,\n",
       " 'xin': 462,\n",
       " 'shampoo': 463,\n",
       " 'right': 464,\n",
       " 'heart': 465,\n",
       " 'show': 466,\n",
       " 'happy': 467,\n",
       " 'full': 468,\n",
       " 'earth': 469,\n",
       " 'receive': 470,\n",
       " 'root': 471,\n",
       " 'tencent': 472,\n",
       " 'late': 473,\n",
       " 'losing': 474,\n",
       " 'japanese': 475,\n",
       " 'move': 476,\n",
       " 'eaten': 477,\n",
       " 'king': 478,\n",
       " 'sun': 479,\n",
       " 'case': 480,\n",
       " 'reduce': 481,\n",
       " 'dog': 482,\n",
       " 'road': 483,\n",
       " 'dragon': 484,\n",
       " 'return': 485,\n",
       " 'gets': 486,\n",
       " 'tsefeng': 487,\n",
       " 'whitening': 488,\n",
       " 'under': 489,\n",
       " 'same': 490,\n",
       " 'lead': 491,\n",
       " '60': 492,\n",
       " 'drivers': 493,\n",
       " 'chicken': 494,\n",
       " 'friend': 495,\n",
       " 'play': 496,\n",
       " 'province': 497,\n",
       " 'please': 498,\n",
       " 'light': 499,\n",
       " 'disinformation': 500,\n",
       " 'zheng': 501,\n",
       " 'photo': 502,\n",
       " 'came': 503,\n",
       " 'name': 504,\n",
       " 'liver': 505,\n",
       " 'revealed': 506,\n",
       " 'try': 507,\n",
       " 'jie': 508,\n",
       " 'already': 509,\n",
       " 'kidney': 510,\n",
       " 'salary': 511,\n",
       " 'quick': 512,\n",
       " 'group': 513,\n",
       " 'function': 514,\n",
       " 'incident': 515,\n",
       " 'prevent': 516,\n",
       " 'special': 517,\n",
       " 'meat': 518,\n",
       " 'hong': 519,\n",
       " 'pan': 520,\n",
       " 'ill': 521,\n",
       " 'save': 522,\n",
       " 'history': 523,\n",
       " 'huawei': 524,\n",
       " 'peoples': 525,\n",
       " 'any': 526,\n",
       " 'girls': 527,\n",
       " 'street': 528,\n",
       " 'yi': 529,\n",
       " 'college': 530,\n",
       " 'divorced': 531,\n",
       " 'entrance': 532,\n",
       " 'morning': 533,\n",
       " 'early': 534,\n",
       " 'teeth': 535,\n",
       " 'huang': 536,\n",
       " 'angry': 537,\n",
       " 'rain': 538,\n",
       " 'turns': 539,\n",
       " 'heavy': 540,\n",
       " 'iphone': 541,\n",
       " 'surgery': 542,\n",
       " 'kill': 543,\n",
       " 'xu': 544,\n",
       " 'start': 545,\n",
       " 'april': 546,\n",
       " 'issued': 547,\n",
       " 'vegetables': 548,\n",
       " 'scene': 549,\n",
       " 'drug': 550,\n",
       " 'find': 551,\n",
       " 'wrong': 552,\n",
       " 'major': 553,\n",
       " 'baoqiang': 554,\n",
       " 'treat': 555,\n",
       " 'tao': 556,\n",
       " 'xie': 557,\n",
       " 'microcredit': 558,\n",
       " 'protruding': 559,\n",
       " 'carcinogenic': 560,\n",
       " 'serious': 561,\n",
       " 'each': 562,\n",
       " 'exam': 563,\n",
       " 'third': 564,\n",
       " 'infected': 565,\n",
       " 'list': 566,\n",
       " 'today': 567,\n",
       " 'broke': 568,\n",
       " 'drop': 569,\n",
       " 'symptoms': 570,\n",
       " 'pure': 571,\n",
       " 'university': 572,\n",
       " 'brother': 573,\n",
       " 'increase': 574,\n",
       " 'accident': 575,\n",
       " 'hua': 576,\n",
       " 'thing': 577,\n",
       " 'boyfriend': 578,\n",
       " 'county': 579,\n",
       " 'insurance': 580,\n",
       " 'prices': 581,\n",
       " 'dead': 582,\n",
       " 'star': 583,\n",
       " 'xian': 584,\n",
       " 'wifi': 585,\n",
       " 'japan': 586,\n",
       " 'earthquake': 587,\n",
       " 'cry': 588,\n",
       " 'broken': 589,\n",
       " 'leave': 590,\n",
       " 'chat': 591,\n",
       " 'doctor': 592,\n",
       " 'onion': 593,\n",
       " 'lets': 594,\n",
       " 'young': 595,\n",
       " 'soon': 596,\n",
       " 'cried': 597,\n",
       " 'coin': 598,\n",
       " 'coins': 599,\n",
       " 'business': 600,\n",
       " 'bank': 601,\n",
       " 'trick': 602,\n",
       " 'starting': 603,\n",
       " 'set': 604,\n",
       " 'foreign': 605,\n",
       " 'matter': 606,\n",
       " 'killed': 607,\n",
       " 'compensation': 608,\n",
       " 'per': 609,\n",
       " 'youre': 610,\n",
       " 'company': 611,\n",
       " 'aliens': 612,\n",
       " 'control': 613,\n",
       " 'able': 614,\n",
       " 'education': 615,\n",
       " 'household': 616,\n",
       " 'rebound': 617,\n",
       " 'taken': 618,\n",
       " 'yu': 619,\n",
       " 'explosion': 620,\n",
       " 'media': 621,\n",
       " 'plus': 622,\n",
       " 'easily': 623,\n",
       " 'spot': 624,\n",
       " 'room': 625,\n",
       " 'liang': 626,\n",
       " 'rules': 627,\n",
       " 'bureau': 628,\n",
       " 'tang': 629,\n",
       " 'between': 630,\n",
       " 'state': 631,\n",
       " 'version': 632,\n",
       " 'traditional': 633,\n",
       " 'smoking': 634,\n",
       " 'collect': 635,\n",
       " 'left': 636,\n",
       " 'called': 637,\n",
       " 'eggs': 638,\n",
       " 'sister': 639,\n",
       " 'story': 640,\n",
       " 'fish': 641,\n",
       " 'myth': 642,\n",
       " 'hit': 643,\n",
       " 'game': 644,\n",
       " 'someone': 645,\n",
       " 'released': 646,\n",
       " 'statement': 647,\n",
       " 'eyes': 648,\n",
       " 'born': 649,\n",
       " 'having': 650,\n",
       " 'healthy': 651,\n",
       " 'picture': 652,\n",
       " 'monthly': 653,\n",
       " 'words': 654,\n",
       " 'fine': 655,\n",
       " 'piece': 656,\n",
       " 'yun': 657,\n",
       " 'green': 658,\n",
       " 'huge': 659,\n",
       " 'coming': 660,\n",
       " 'qing': 661,\n",
       " 'law': 662,\n",
       " 'hundred': 663,\n",
       " 'formaldehyde': 664,\n",
       " 'work': 665,\n",
       " 'rate': 666,\n",
       " 'thats': 667,\n",
       " 'crazy': 668,\n",
       " 'responded': 669,\n",
       " 'future': 670,\n",
       " 'boys': 671,\n",
       " 'whiten': 672,\n",
       " 'own': 673,\n",
       " 'shanghai': 674,\n",
       " 'foot': 675,\n",
       " '12': 676,\n",
       " 'kong': 677,\n",
       " 'thousands': 678,\n",
       " 'alien': 679,\n",
       " 'fees': 680,\n",
       " 'sell': 681,\n",
       " 'domestic': 682,\n",
       " 'station': 683,\n",
       " 'gone': 684,\n",
       " 'egg': 685,\n",
       " 'pension': 686,\n",
       " 'rise': 687,\n",
       " 'fruits': 688,\n",
       " 'cheung': 689,\n",
       " 'charge': 690,\n",
       " 'completely': 691,\n",
       " 'report': 692,\n",
       " 'changed': 693,\n",
       " 'disc': 694,\n",
       " 'millions': 695,\n",
       " 'eye': 696,\n",
       " 'spend': 697,\n",
       " 'expert': 698,\n",
       " 'profit': 699,\n",
       " 'close': 700,\n",
       " 'nt': 701,\n",
       " 'rong': 702,\n",
       " 'human': 703,\n",
       " 'nine': 704,\n",
       " 'understand': 705,\n",
       " 'dare': 706,\n",
       " 'where': 707,\n",
       " 'doesnt': 708,\n",
       " 'lumbar': 709,\n",
       " 'didnt': 710,\n",
       " 'nemesis': 711,\n",
       " 'record': 712,\n",
       " 'paid': 713,\n",
       " 'keep': 714,\n",
       " 'treasure': 715,\n",
       " 'electric': 716,\n",
       " 'die': 717,\n",
       " 'stage': 718,\n",
       " 'cut': 719,\n",
       " 'development': 720,\n",
       " 'suicide': 721,\n",
       " 'hes': 722,\n",
       " 'detained': 723,\n",
       " 'line': 724,\n",
       " 'password': 725,\n",
       " '9': 726,\n",
       " 'online': 727,\n",
       " 'micro': 728,\n",
       " 'types': 729,\n",
       " 'bought': 730,\n",
       " 'answer': 731,\n",
       " 'glory': 732,\n",
       " 'large': 733,\n",
       " 'care': 734,\n",
       " 'hand': 735,\n",
       " 'wonder': 736,\n",
       " 'drunk': 737,\n",
       " 'arrested': 738,\n",
       " 'problem': 739,\n",
       " 'deer': 740,\n",
       " 'asked': 741,\n",
       " 'tv': 742,\n",
       " 'airport': 743,\n",
       " 'season': 744,\n",
       " 'building': 745,\n",
       " 'bing': 746,\n",
       " 'poor': 747,\n",
       " 'flower': 748,\n",
       " 'teaches': 749,\n",
       " 'gas': 750,\n",
       " 'prison': 751,\n",
       " 'deal': 752,\n",
       " 'host': 753,\n",
       " 'chengdu': 754,\n",
       " 'several': 755,\n",
       " 'toothpaste': 756,\n",
       " 'makes': 757,\n",
       " 'then': 758,\n",
       " 'heard': 759,\n",
       " 'officially': 760,\n",
       " 'always': 761,\n",
       " 'anticancer': 762,\n",
       " 'fact': 763,\n",
       " 'movie': 764,\n",
       " 'seconds': 765,\n",
       " 'emergency': 766,\n",
       " 'since': 767,\n",
       " 'dispel': 768,\n",
       " 'bridge': 769,\n",
       " '18': 770,\n",
       " 'middle': 771,\n",
       " 'cecilia': 772,\n",
       " 'stars': 773,\n",
       " 'took': 774,\n",
       " 'district': 775,\n",
       " 'sold': 776,\n",
       " 'reform': 777,\n",
       " 'responds': 778,\n",
       " 'river': 779,\n",
       " 'jing': 780,\n",
       " 'war': 781,\n",
       " 'suddenly': 782,\n",
       " 'machine': 783,\n",
       " 'reported': 784,\n",
       " 'gray': 785,\n",
       " 'system': 786,\n",
       " 'radiation': 787,\n",
       " 'confirmed': 788,\n",
       " 'cervical': 789,\n",
       " 'behind': 790,\n",
       " 'daughterinlaw': 791,\n",
       " 'cough': 792,\n",
       " 'check': 793,\n",
       " 'benefits': 794,\n",
       " 'area': 795,\n",
       " 'enough': 796,\n",
       " 'went': 797,\n",
       " 'photos': 798,\n",
       " 'detoxify': 799,\n",
       " 'fall': 800,\n",
       " 'looks': 801,\n",
       " 'immediately': 802,\n",
       " 'studio': 803,\n",
       " 'master': 804,\n",
       " 'luo': 805,\n",
       " 'everyone': 806,\n",
       " 'hunan': 807,\n",
       " 'cheated': 808,\n",
       " 'shenzhen': 809,\n",
       " 'cheating': 810,\n",
       " 'ho': 811,\n",
       " 'beat': 812,\n",
       " 'breast': 813,\n",
       " 'build': 814,\n",
       " 'owners': 815,\n",
       " 'jiang': 816,\n",
       " 'expected': 817,\n",
       " 'turned': 818,\n",
       " 'told': 819,\n",
       " 'yearold': 820,\n",
       " 'directly': 821,\n",
       " 'vehicles': 822,\n",
       " 'military': 823,\n",
       " 'later': 824,\n",
       " 'youll': 825,\n",
       " 'comes': 826,\n",
       " 'luxury': 827,\n",
       " 'difficult': 828,\n",
       " 'estate': 829,\n",
       " 'share': 830,\n",
       " 'signal': 831,\n",
       " 'wild': 832,\n",
       " 'notice': 833,\n",
       " '40': 834,\n",
       " 'missing': 835,\n",
       " 'july': 836,\n",
       " 'winter': 837,\n",
       " 'mouth': 838,\n",
       " 'fly': 839,\n",
       " 'beer': 840,\n",
       " 'microletter': 841,\n",
       " 'drive': 842,\n",
       " 'attack': 843,\n",
       " 'caused': 844,\n",
       " 'forced': 845,\n",
       " 'qin': 846,\n",
       " 'yellow': 847,\n",
       " 'daily': 848,\n",
       " 'careful': 849,\n",
       " 'actually': 850,\n",
       " 'guangdong': 851,\n",
       " 'place': 852,\n",
       " 'hands': 853,\n",
       " 'farmer': 854,\n",
       " 'unk': 855,\n",
       " 'god': 856,\n",
       " 'ago': 857,\n",
       " 'nothing': 858,\n",
       " 'spreading': 859,\n",
       " 'seen': 860,\n",
       " 'driver': 861,\n",
       " 'kids': 862,\n",
       " 'guan': 863,\n",
       " 'hu': 864,\n",
       " 'service': 865,\n",
       " 'order': 866,\n",
       " 'annual': 867,\n",
       " 'those': 868,\n",
       " 'super': 869,\n",
       " 'gold': 870,\n",
       " 'drugs': 871,\n",
       " 'single': 872,\n",
       " 'clear': 873,\n",
       " 'refute': 874,\n",
       " 'ying': 875,\n",
       " 'cost': 876,\n",
       " 'hurry': 877,\n",
       " 'join': 878,\n",
       " 'gave': 879,\n",
       " 'plane': 880,\n",
       " 'shes': 881,\n",
       " 'poisoned': 882,\n",
       " 'soup': 883,\n",
       " 'medical': 884,\n",
       " 'point': 885,\n",
       " 'houses': 886,\n",
       " 'ever': 887,\n",
       " 'caught': 888,\n",
       " 'im': 889,\n",
       " 'selfmade': 890,\n",
       " 'empty': 891,\n",
       " 'catch': 892,\n",
       " 'student': 893,\n",
       " 'moth': 894,\n",
       " 'yao': 895,\n",
       " 'common': 896,\n",
       " 'standard': 897,\n",
       " 'glass': 898,\n",
       " 'guo': 899,\n",
       " 'looking': 900,\n",
       " 'call': 901,\n",
       " 'construction': 902,\n",
       " 'unexpectedly': 903,\n",
       " 'recipe': 904,\n",
       " 'bowl': 905,\n",
       " 'action': 906,\n",
       " 'reveals': 907,\n",
       " 'evening': 908,\n",
       " 'smooth': 909,\n",
       " 'xiao': 910,\n",
       " 'shooting': 911,\n",
       " 'shares': 912,\n",
       " 'eats': 913,\n",
       " 'xun': 914,\n",
       " 'our': 915,\n",
       " 'crying': 916,\n",
       " 'tens': 917,\n",
       " 'honey': 918,\n",
       " 'hours': 919,\n",
       " 'restore': 920,\n",
       " 'practical': 921,\n",
       " 'jumped': 922,\n",
       " 'abolished': 923,\n",
       " 'party': 924,\n",
       " 'biggest': 925,\n",
       " 'train': 926,\n",
       " 'cast': 927,\n",
       " 'andy': 928,\n",
       " 'hidden': 929,\n",
       " 'done': 930,\n",
       " 'using': 931,\n",
       " 'ministry': 932,\n",
       " 'vehicle': 933,\n",
       " 'key': 934,\n",
       " 'drops': 935,\n",
       " 'methods': 936,\n",
       " 'registration': 937,\n",
       " 'bus': 938,\n",
       " 'retirement': 939,\n",
       " 'town': 940,\n",
       " 'original': 941,\n",
       " 'speed': 942,\n",
       " 'through': 943,\n",
       " 'examination': 944,\n",
       " 'younger': 945,\n",
       " 'moths': 946,\n",
       " 'amazing': 947,\n",
       " 'qi': 948,\n",
       " 'moon': 949,\n",
       " 'hairs': 950,\n",
       " 'far': 951,\n",
       " 'office': 952,\n",
       " 'lung': 953,\n",
       " 'benshan': 954,\n",
       " 'tong': 955,\n",
       " 'saying': 956,\n",
       " 'south': 957,\n",
       " 'support': 958,\n",
       " 'fresh': 959,\n",
       " 'babys': 960,\n",
       " 'run': 961,\n",
       " 'glue': 962,\n",
       " 'eliminate': 963,\n",
       " 'football': 964,\n",
       " 'shot': 965,\n",
       " 'kaiwei': 966,\n",
       " 'while': 967,\n",
       " 'illness': 968,\n",
       " 'sang': 969,\n",
       " 'deep': 970,\n",
       " 'deleted': 971,\n",
       " 'theyre': 972,\n",
       " 'fell': 973,\n",
       " 'association': 974,\n",
       " 'mothers': 975,\n",
       " 'north': 976,\n",
       " 'increased': 977,\n",
       " 'homemade': 978,\n",
       " 'dynasty': 979,\n",
       " 'bai': 980,\n",
       " 'collapse': 981,\n",
       " 'certificate': 982,\n",
       " 'owner': 983,\n",
       " 'recently': 984,\n",
       " 'around': 985,\n",
       " 'dark': 986,\n",
       " 'spots': 987,\n",
       " 'wolf': 988,\n",
       " 'making': 989,\n",
       " 'tips': 990,\n",
       " 'withdraw': 991,\n",
       " 'june': 992,\n",
       " 'brain': 993,\n",
       " 'bao': 994,\n",
       " 'workers': 995,\n",
       " 'exercise': 996,\n",
       " 'american': 997,\n",
       " 'double': 998,\n",
       " 'flowers': 999,\n",
       " '200': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://keras.io/preprocessing/text/\n",
    "- https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n",
    "- https://www.youtube.com/watch?v=j-3vuBynnOE - Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2\n",
    "\n",
    "- http://faroit.com/keras-docs/1.2.2/preprocessing/text/#tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
