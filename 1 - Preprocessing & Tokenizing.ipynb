{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -------------- Preprocessing Packages --------------\n",
    "# For tokenizing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------- General Packages --------------\n",
    "# General Use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Saving Files\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters corrupted, unusable/unused data from the dataset\n",
    "def filter_dataset(df):\n",
    "    df = df.drop(columns=['id','tid1','tid2']) # drop id columns\n",
    "    df = df.drop(columns=['title1_zh','title2_zh']) # drop chinese columns\n",
    "\n",
    "    # Remove symbols\n",
    "    df['title1_en'] = df['title1_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "    df['title2_en'] = df['title2_en'].str.replace('[^a-zA-Z0-9 ]','')\n",
    "\n",
    "    # Replace empty strings with NaN values\n",
    "    df['title1_en'].replace('', np.nan, inplace=True)\n",
    "    df['title2_en'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    # Remove rows with no label\n",
    "    labels = ['unrelated','agreed','disagreed']\n",
    "    df = df[df.label.isin(labels)]\n",
    "    \n",
    "    # Remove Unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Drop rows with null values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Returns a datset with an equal sampling of each label\n",
    "def equalize_dataset_labels(df, seed=1):\n",
    "    # Get minimum label count\n",
    "    n = df.label.value_counts().min()\n",
    "    \n",
    "    # Grabbing equal amounts of training data from each class\n",
    "    dfa = df[df['label']=='unrelated'].sample(n,random_state=seed)\n",
    "    dfb = df[df['label']=='agreed'].sample(n,random_state=seed)\n",
    "    dfc = df[df['label']=='disagreed'].sample(n,random_state=seed)\n",
    "    \n",
    "    # Recombine dataset and shuffle\n",
    "    df = pd.concat([dfa,dfb,dfc])\n",
    "    df = df.sample(frac=1,random_state=seed)\n",
    "    return df\n",
    "\n",
    "# Convert labels to integers for predictions\n",
    "def encode_labels(df):\n",
    "    # encoding the labels\n",
    "    labels = {'unrelated':0,'agreed':1,'disagreed':2}\n",
    "    df['label'].replace(labels,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word tokenizer given dataframe(s)\n",
    "def create_tokenizer(*data, split=' ', filename='tokenizer'):\n",
    "    # create the tokenizer\n",
    "    t = Tokenizer(oov_token=True, split=split)\n",
    "    \n",
    "    # fit tokenizer\n",
    "    for df in data:\n",
    "        t.fit_on_texts(df['title1_en'])  \n",
    "        t.fit_on_texts(df['title2_en'])  \n",
    "    \n",
    "    # save for future use\n",
    "    pickle_out = open(filename+'.pickle', 'wb')\n",
    "    pickle.dump(t,pickle_out)\n",
    "    pickle_out.close()\n",
    "    return t\n",
    "\n",
    "# Tokenizes titles and encodes labels, trains a word tokenizer that is saved to a file\n",
    "def tokenize(t, df, maxlen=20):\n",
    "    # fit the tokenizer on the documents  \n",
    "    data1 = pad_sequences(sequences=t.texts_to_sequences(df['title1_en']), maxlen=maxlen)\n",
    "    data2 = pad_sequences(sequences=t.texts_to_sequences(df['title2_en']), maxlen=maxlen)\n",
    "    \n",
    "    # recombine\n",
    "    df = pd.DataFrame(np.concatenate((data1,data2),axis=1)).join(df['label'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Preprocessed/Tokenized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given train and test data, split into features and labels and save\n",
    "def save_data(train, test, maxlen=20, save_dir='./split_data/'):\n",
    "    # Split the data into X and y\n",
    "    X_train = train.iloc[:,:maxlen*2].to_numpy()\n",
    "    X_test = test.iloc[:,:maxlen*2].to_numpy()\n",
    "    y_train = train['label'].to_numpy()\n",
    "    y_test = test['label'].to_numpy()\n",
    "\n",
    "    # reshape the X train data for use\n",
    "    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "    \n",
    "    split_data_dir=save_dir\n",
    "    os.makedirs(os.path.dirname(split_data_dir), exist_ok=True)\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_train.pickle', 'wb')\n",
    "    pickle.dump(X_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'X_test.pickle', 'wb')\n",
    "    pickle.dump(X_test,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(split_data_dir+'y_train.pickle', 'wb')\n",
    "    pickle.dump(y_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open(split_data_dir+'y_test.pickle', 'wb')\n",
    "    pickle.dump(y_test,pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7026: expected 8 fields, saw 9\\nSkipping line 44341: expected 8 fields, saw 9\\nSkipping line 58784: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 99101: expected 8 fields, saw 10\\nSkipping line 104716: expected 8 fields, saw 9\\nSkipping line 127866: expected 8 fields, saw 10\\n'\n",
      "b'Skipping line 140436: expected 8 fields, saw 9\\nSkipping line 152888: expected 8 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "input_train = './data/train.csv'\n",
    "input_validation = './data/validation.csv'\n",
    "\n",
    "df_train = pd.read_csv(input_train,encoding='utf-8-sig',error_bad_lines=False)\n",
    "df_test = pd.read_csv(input_validation,encoding='utf-8-sig',error_bad_lines=False)\n",
    "\n",
    "df_train = filter_dataset(df_train)\n",
    "df_test = filter_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_tokenizer(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_equalized = equalize_dataset_labels(df_train)\n",
    "df_test_equalized = equalize_dataset_labels(df_test)\n",
    "\n",
    "df_train_encoded = encode_labels(df_train_equalized)\n",
    "df_test_encoded = encode_labels(df_test_equalized)\n",
    "\n",
    "df_train_tokenized = tokenize(t,df_train_encoded,20)\n",
    "df_test_tokenized = tokenize(t,df_test_encoded,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train=df_train_tokenized,test=df_test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Tokenization\n",
    "\n",
    "Some experimentation with inverse tokenizing to double check if it's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at last the loch ness monster was captured and it is said to be the most recognizable of all time']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sequences_to_texts([df_train_tokenized.iloc[0,:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the american scientist has finally caught the clear loch ness monster its terrible']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sequences_to_texts([df_train_tokenized.iloc[0,27:40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tokenized.iloc[0,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5040</td>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>The American scientist has finally caught the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          title1_en  \\\n",
       "0   5040  At last the Loch Ness Monster was captured and...   \n",
       "\n",
       "                                           title2_en  label  \n",
       "0  The American scientist has finally caught the ...      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some people say that cabbage is the king of po...</td>\n",
       "      <td>Maradona talks about health Im better than eve...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secretly the pharmacy has a cheap cream put on...</td>\n",
       "      <td>Dont be a fool to get the bags under your eyes...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just at 23 28 the Chinese stock market broke a...</td>\n",
       "      <td>China stock market startling news the words of...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the most powerful legion in World War ...</td>\n",
       "      <td>The three great rumblings of the Second World ...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Discovery of Miracles of Medical Miracles The ...</td>\n",
       "      <td>Why is red wine fighting cancer</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title1_en  \\\n",
       "0  Some people say that cabbage is the king of po...   \n",
       "1  Secretly the pharmacy has a cheap cream put on...   \n",
       "2  Just at 23 28 the Chinese stock market broke a...   \n",
       "3  Who was the most powerful legion in World War ...   \n",
       "4  Discovery of Miracles of Medical Miracles The ...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  Maradona talks about health Im better than eve...  unrelated  \n",
       "1  Dont be a fool to get the bags under your eyes...     agreed  \n",
       "2  China stock market startling news the words of...  unrelated  \n",
       "3  The three great rumblings of the Second World ...  unrelated  \n",
       "4                    Why is red wine fighting cancer  unrelated  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>The American scientist has finally caught the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100367</th>\n",
       "      <td>Hair takes a lot of nourishment</td>\n",
       "      <td>A big  ass kid A long shot to get nourishment ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190245</th>\n",
       "      <td>Diabetics get addicted to insulin</td>\n",
       "      <td>Is it addictive to take insulin Its not too la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>The survival of the jedi is brought with the r...</td>\n",
       "      <td>Tencent disbarredly PUBG national service anno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46092</th>\n",
       "      <td>The first spoony girl in sports miss yao ming ...</td>\n",
       "      <td>China Womens Volleyball Team Announces 14 Peop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title1_en  \\\n",
       "5040    At last the Loch Ness Monster was captured and...   \n",
       "100367                    Hair takes a lot of nourishment   \n",
       "190245                  Diabetics get addicted to insulin   \n",
       "17046   The survival of the jedi is brought with the r...   \n",
       "46092   The first spoony girl in sports miss yao ming ...   \n",
       "\n",
       "                                                title2_en  label  \n",
       "5040    The American scientist has finally caught the ...      1  \n",
       "100367  A big  ass kid A long shot to get nourishment ...      2  \n",
       "190245  Is it addictive to take insulin Its not too la...      1  \n",
       "17046   Tencent disbarredly PUBG national service anno...      0  \n",
       "46092   China Womens Volleyball Team Announces 14 Peop...      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_equalized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>A foreign internet friend captured shocking fo...</td>\n",
       "      <td>Amateurs take pictures of the Loch Ness Monster</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>The American scientist has finally caught the ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man waited for the Loch Ness monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34735</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man waited for the Loch Ness monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50927</th>\n",
       "      <td>The old man stayed for twentysix years with th...</td>\n",
       "      <td>The old man waited for the Loch Ness monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51102</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man stayed with the Loch Ness monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58844</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man waited for the Loch Ness monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59720</th>\n",
       "      <td>The Loch Ness Monster Scientists will use DNA ...</td>\n",
       "      <td>The mysterious thing of legend finally appeare...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75914</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man stayed with the Loch Ness Monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83149</th>\n",
       "      <td>The old man stayed with the Loch Ness monster ...</td>\n",
       "      <td>The old man waited for the Loch Ness monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96248</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100261</th>\n",
       "      <td>The Loch Ness Monster shows up for photographs</td>\n",
       "      <td>Amateurs take pictures of the Loch Ness Monster</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108470</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man spent 26 years taking pictures of ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111153</th>\n",
       "      <td>The Loch Ness Monster Scientists will use DNA ...</td>\n",
       "      <td>Some of the mystical creatures of the folklore...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113214</th>\n",
       "      <td>i  26 years old   i   i  making the most visi...</td>\n",
       "      <td>The old man stayed with the Loch Ness Monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115797</th>\n",
       "      <td>The Loch Ness Monster Scientists will use DNA ...</td>\n",
       "      <td>Five mythical creatures of the ancient legends</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116013</th>\n",
       "      <td>The old man stayed for twentysix years with th...</td>\n",
       "      <td>The old man stayed with the Loch Ness monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116447</th>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>Amateurs take pictures of the Loch Ness Monster</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121144</th>\n",
       "      <td>The Loch Ness Monster Scientists will use DNA ...</td>\n",
       "      <td>Its so weird Its a mysterious creature from th...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136434</th>\n",
       "      <td>i  26 years old   i   i  making the most visi...</td>\n",
       "      <td>The old man spent 26 years taking pictures of ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148830</th>\n",
       "      <td>It took 26 years to finally get a picture of t...</td>\n",
       "      <td>The old man spent 26 years taking pictures of ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151193</th>\n",
       "      <td>i  26 years old   i   i  making the most visi...</td>\n",
       "      <td>It took an old man in England 26 years to take...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154349</th>\n",
       "      <td>It took 26 years to finally get a picture of t...</td>\n",
       "      <td>The old man stayed with the Loch Ness Monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166560</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>It took an old man in England 26 years to take...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169977</th>\n",
       "      <td>The old man waited for the Loch Ness Monster f...</td>\n",
       "      <td>The old man stayed for twentysix years with th...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174488</th>\n",
       "      <td>British Fisherman Loch Ness caught on videotap...</td>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183969</th>\n",
       "      <td>At last the Loch Ness Monster was captured and...</td>\n",
       "      <td>The Loch Ness Monster shows up for photographs</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185725</th>\n",
       "      <td>It took an old man in England 26 years to take...</td>\n",
       "      <td>The old man stayed with the Loch Ness Monster ...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title1_en  \\\n",
       "963     A foreign internet friend captured shocking fo...   \n",
       "5040    At last the Loch Ness Monster was captured and...   \n",
       "27978   The old man waited for the Loch Ness Monster f...   \n",
       "34735   The old man waited for the Loch Ness Monster f...   \n",
       "50927   The old man stayed for twentysix years with th...   \n",
       "51102   The old man waited for the Loch Ness Monster f...   \n",
       "58844   The old man waited for the Loch Ness Monster f...   \n",
       "59720   The Loch Ness Monster Scientists will use DNA ...   \n",
       "75914   The old man waited for the Loch Ness Monster f...   \n",
       "83149   The old man stayed with the Loch Ness monster ...   \n",
       "96248   The old man waited for the Loch Ness Monster f...   \n",
       "100261     The Loch Ness Monster shows up for photographs   \n",
       "108470  The old man waited for the Loch Ness Monster f...   \n",
       "111153  The Loch Ness Monster Scientists will use DNA ...   \n",
       "113214   i  26 years old   i   i  making the most visi...   \n",
       "115797  The Loch Ness Monster Scientists will use DNA ...   \n",
       "116013  The old man stayed for twentysix years with th...   \n",
       "116447  At last the Loch Ness Monster was captured and...   \n",
       "121144  The Loch Ness Monster Scientists will use DNA ...   \n",
       "136434   i  26 years old   i   i  making the most visi...   \n",
       "148830  It took 26 years to finally get a picture of t...   \n",
       "151193   i  26 years old   i   i  making the most visi...   \n",
       "154349  It took 26 years to finally get a picture of t...   \n",
       "166560  The old man waited for the Loch Ness Monster f...   \n",
       "169977  The old man waited for the Loch Ness Monster f...   \n",
       "174488  British Fisherman Loch Ness caught on videotap...   \n",
       "183969  At last the Loch Ness Monster was captured and...   \n",
       "185725  It took an old man in England 26 years to take...   \n",
       "\n",
       "                                                title2_en      label  \n",
       "963       Amateurs take pictures of the Loch Ness Monster     agreed  \n",
       "5040    The American scientist has finally caught the ...     agreed  \n",
       "27978   The old man waited for the Loch Ness monster f...     agreed  \n",
       "34735   The old man waited for the Loch Ness monster f...     agreed  \n",
       "50927   The old man waited for the Loch Ness monster f...     agreed  \n",
       "51102   The old man stayed with the Loch Ness monster ...     agreed  \n",
       "58844   The old man waited for the Loch Ness monster f...     agreed  \n",
       "59720   The mysterious thing of legend finally appeare...  unrelated  \n",
       "75914   The old man stayed with the Loch Ness Monster ...     agreed  \n",
       "83149   The old man waited for the Loch Ness monster f...     agreed  \n",
       "96248   The old man waited for the Loch Ness Monster f...     agreed  \n",
       "100261    Amateurs take pictures of the Loch Ness Monster     agreed  \n",
       "108470  The old man spent 26 years taking pictures of ...     agreed  \n",
       "111153  Some of the mystical creatures of the folklore...  unrelated  \n",
       "113214  The old man stayed with the Loch Ness Monster ...     agreed  \n",
       "115797     Five mythical creatures of the ancient legends  unrelated  \n",
       "116013  The old man stayed with the Loch Ness monster ...     agreed  \n",
       "116447    Amateurs take pictures of the Loch Ness Monster     agreed  \n",
       "121144  Its so weird Its a mysterious creature from th...  unrelated  \n",
       "136434  The old man spent 26 years taking pictures of ...     agreed  \n",
       "148830  The old man spent 26 years taking pictures of ...     agreed  \n",
       "151193  It took an old man in England 26 years to take...     agreed  \n",
       "154349  The old man stayed with the Loch Ness Monster ...     agreed  \n",
       "166560  It took an old man in England 26 years to take...     agreed  \n",
       "169977  The old man stayed for twentysix years with th...     agreed  \n",
       "174488  At last the Loch Ness Monster was captured and...     agreed  \n",
       "183969     The Loch Ness Monster shows up for photographs     agreed  \n",
       "185725  The old man stayed with the Loch Ness Monster ...     agreed  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.title1_en.str.contains('Loch Ness')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://keras.io/preprocessing/text/\n",
    "- https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n",
    "- https://www.youtube.com/watch?v=j-3vuBynnOE - Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2\n",
    "\n",
    "- http://faroit.com/keras-docs/1.2.2/preprocessing/text/#tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
